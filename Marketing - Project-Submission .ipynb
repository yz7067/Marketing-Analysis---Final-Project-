{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing Analysis -- Final Project \n",
    "## Code Session \n",
    "## Yiyin Zhang (yz7067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "\n",
    "a = np.array(cust['age'])\n",
    "ax.hist(a, bins = [0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110], rwidth=0.5)\n",
    "#ax.set_title('age', fontsize=20)\n",
    "ax.set_xticks([0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110])\n",
    "ax.set_xlabel('age', fontsize=20)\n",
    "ax.set_ylabel('subscriber count', fontsize=20)\n",
    "\n",
    "plt.savefig('age distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=2)\n",
    "f, ax = plt.subplots(figsize=(45,10))\n",
    "sns.countplot(x='num_ideal_streaming_services',data=df)#palette = ['#8e1f0b','#db6d25ff', '#ffb03bff','#ffce4bff'])\n",
    "#pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
    "plt.ticklabel_format(style='plain', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Customer Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('subscribers-updated.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1,)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,len(df)):\n",
    "    if df.loc[n,'age'] > 2018:\n",
    "        df.loc[n,'age'] = None\n",
    "    elif df.loc[n,'age'] > 1929:\n",
    "        df.loc[n,'age'] = 2019 - df.loc[n,'age']\n",
    "    elif df.loc[n,'age'] > 108:\n",
    "        df.loc[n,'age'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop age's negative value\n",
    "df=df[df['age']>0]\n",
    "#Drop weekly_consumption_hour's negative value\n",
    "df=df[df['weekly_consumption_hour']>0]\n",
    "#Drop num_ideal_streaming_services's negative value\n",
    "df=df[df['num_ideal_streaming_services']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['package_type','preferred_genre','intended_use','weekly_consumption_hour','age','op_sys','male_TF'],inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cust = df[['subid', 'package_type', 'num_weekly_services_utilized',\n",
    "       'preferred_genre', 'intended_use', 'weekly_consumption_hour','num_ideal_streaming_services',\n",
    "       'age', 'male_TF','attribution_technical', 'op_sys']]\n",
    "cust.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numweek = cust.num_weekly_services_utilized.mean()\n",
    "numideal = cust.num_ideal_streaming_services.mean()\n",
    "cust['num_weekly_services_utilized'].fillna(numweek,inplace=True)\n",
    "cust['num_ideal_streaming_services'].fillna(numideal,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custdum=pd.get_dummies(cust,drop_first = True)\n",
    "custdum.info()\n",
    "custdumnoid = custdum.iloc[:,1:50] #Remove subid columns\n",
    "custdumnoid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmaxscaler = MinMaxScaler()\n",
    "custdumnoid_scaled = minmaxscaler.fit_transform(custdumnoid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inertia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# criterion: inertia #看平的点\n",
    "inertias = {}\n",
    "for k in range(2, 20):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=2020)\n",
    "    kmeans.fit(custdumnoid_scaled)  # here we do not use fit_transform since we don't need the transformed result\n",
    "    inertias[k] = kmeans.inertia_\n",
    "print(inertias) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #select: 5?\n",
    "f, ax = plt.subplots(figsize=(30,10))\n",
    "ax = plt.subplot()\n",
    "ax.plot(list(inertias.keys()), list(inertias.values()) ,'-*')\n",
    "ax.set_xticks(np.arange(2, 20))\n",
    "#ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=1996)\n",
    "y_pred = kmeans.fit_predict(custdumnoid_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the cluster number back to \n",
    "custclus = pd.DataFrame(cust)\n",
    "custclus['cluster'] = y_pred\n",
    "custclus['cluster'].value_counts()\n",
    "custclus=custclus.reset_index()\n",
    "custclus.drop('index',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custclus.to_csv('cluster4F.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Attribution Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Considering the user converted with revenue generated: \n",
    "## and considering spend on that channel worths \n",
    "### Payment_period >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('subscribers-updated.csv',parse_dates=['account_creation_date'])\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "spe = pd.read_csv('channel_spend_graduate.csv')\n",
    "spe1 = pd.read_csv('channel_spend_graduate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = df[['subid', 'attribution_technical','attribution_survey','account_creation_date','payment_period','trial_completed']]\n",
    "att.dropna(subset = ['attribution_survey'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out paymeent_period == 0 and trial_completed = True\n",
    "att1 = att[(att['payment_period']!=0) & (att['trial_completed'] == True)]\n",
    "att1.reset_index(inplace=True)\n",
    "att1.drop('index',axis='columns', inplace=True)\n",
    "\n",
    "att1.loc[:,('date')] = att1['account_creation_date'].dt.strftime('%Y%m')\n",
    "att1.loc[:,('date')] = att1['date'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribution_Technical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(0,len(spe)):\n",
    "    channel = spe.loc[m,'channel']\n",
    "    date = spe.loc[m,'date']\n",
    "    subattri= att1[(att1['date'] == date) & (att1['attribution_technical'] == channel)]\n",
    "    spe.loc[m,'count'] = len(subattri)\n",
    "    spe.loc[m,'Average_CAC_Tech'] = spe.loc[m,'spend_AED']/spe.loc[m,'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speMt = spe.sort_values(['channel','spend_AED'],ascending=True)\n",
    "speMt.reset_index(inplace=True)\n",
    "speMt.drop('index',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,len(speMt)):\n",
    "    if speMt.loc[n,'channel'] == speMt.loc[(n-1),'channel']:\n",
    "        speMt.loc[n,'Marginal_CAC_Tech'] = (speMt.loc[n,'spend_AED'] - speMt.loc[(n-1),'spend_AED'])/(speMt.loc[n,'count'] - speMt.loc[(n-1),'count'])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for m in [0,8,16,24,32]:\n",
    "    speMt.loc[m,'Marginal_CAC_Tech'] = speMt.loc[m,'spend_AED'] /speMt.loc[m,'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speMt.to_csv(\"Attri_Technical.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribution_Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(0,len(spe1)):\n",
    "    channel = spe1.loc[m,'channel']\n",
    "    date = spe1.loc[m,'date']\n",
    "    subattri= att1[(att1['date'] == date) & (att1['attribution_survey'] == channel)]\n",
    "    spe1.loc[m,'count'] = len(subattri)\n",
    "    spe1.loc[m,'Average_CAC_Sur'] = spe1.loc[m,'spend_AED']/spe1.loc[m,'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speMs = spe1.sort_values(['channel','spend_AED'],ascending=True)\n",
    "speMs.reset_index(inplace=True)\n",
    "speMs.drop('index',axis='columns', inplace=True)\n",
    "speMs = speMs.loc[16:39,]\n",
    "speMs.reset_index(inplace=True)\n",
    "speMs.drop('index',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,len(speMs)):\n",
    "    if speMs.loc[n,'channel'] == speMs.loc[(n-1),'channel']:\n",
    "        speMs.loc[n,'Marginal_CAC_Sur'] = (speMs.loc[n,'spend_AED'] - speMs.loc[(n-1),'spend_AED'])/(speMs.loc[n,'count'] - speMs.loc[(n-1),'count'])\n",
    "    else:\n",
    "        continue\n",
    "for m in [0,8,16]:\n",
    "    speMs.loc[m,'Marginal_CAC_Sur'] = speMs.loc[m,'spend_AED'] /speMs.loc[m,'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speMs.to_csv(\"Attri_Survey.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Churn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('subscribers-updated.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1,)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with abnormal value\n",
    "for n in range(0,len(df)):\n",
    "    if df.loc[n,'age'] > 2018:\n",
    "        df.loc[n,'age'] = None\n",
    "    elif df.loc[n,'age'] > 1929:\n",
    "        df.loc[n,'age'] = 2019 - df.loc[n,'age']\n",
    "    elif df.loc[n,'age'] > 108:\n",
    "        df.loc[n,'age'] = None\n",
    "\n",
    "# drop negative value:\n",
    "df=df[df['age']>0]\n",
    "df=df[df['weekly_consumption_hour']>0]\n",
    "df=df[df['num_ideal_streaming_services']>0]\n",
    "\n",
    "numweek = df.num_weekly_services_utilized.mean()\n",
    "numideal = df.num_ideal_streaming_services.mean()\n",
    "df['num_weekly_services_utilized'].fillna(numweek,inplace=True)\n",
    "df['num_ideal_streaming_services'].fillna(numideal,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create x-value form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = df[['subid', 'package_type', 'num_weekly_services_utilized',\n",
    "       'preferred_genre', 'intended_use', 'weekly_consumption_hour',\n",
    "        'num_ideal_streaming_services','age', 'male_TF','attribution_technical',\n",
    "        'op_sys','join_fee','plan_type','payment_period','account_creation_date','cancel_date']]\n",
    "\n",
    "churn['account_creation_date'] = pd.to_datetime(churn['account_creation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn =  churn[churn['plan_type']=='base_uae_14_day_trial']\n",
    "churn.dropna(subset=['package_type','preferred_genre'],inplace=True)\n",
    "churn = churn.reset_index()\n",
    "churn.drop('index',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Create user churn Y = 1, p = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 period_0 + Trial End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialend1 = churnp0[((churnp0['account_creation_date']<= '2020-03-13 00:00:00') == True)]\n",
    "trialend2 = churnp0[(churnp0['cancel_date'].isnull() == True)]\n",
    "trialend = churnp0[((churnp0['account_creation_date']<= '2020-03-13 00:00:00') == True) & (churnp0['cancel_date'].isnull() == True)]\n",
    "len(trialend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 period_0 + Active Cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actcancel = churnp0[(churnp0['cancel_date'].isnull() == False)]\n",
    "len(actcancel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine \n",
    "combine = [trialend,actcancel]\n",
    "churny1 = pd.concat(combine)\n",
    "len(churn)\n",
    "churny1['churn'] = 1\n",
    "churny1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create user churn Y = 0,  p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nochurn = churn[((churn['payment_period'] > 0) == True)]\n",
    "churny0 = churn[churn['payment_period'] > 0]\n",
    "churny0['churn'] = 0\n",
    "len(churny0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Combine Y =1 & Y= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [churny1,churny0]\n",
    "trval =  pd.concat(combine)\n",
    "\n",
    "trval = trval.reset_index()\n",
    "trval.drop('index',axis='columns', inplace=True)\n",
    "#trval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. user-not decided Y = ?, p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undecide1 = churnp0[((churnp0['account_creation_date']<= '2020-03-13 00:00:00') == False)]\n",
    "undecide2 = churnp0[(churnp0['cancel_date'].isnull() == True)]\n",
    "undecide = churnp0[((churnp0['account_creation_date']<= '2020-03-13 00:00:00') == False) & (churnp0['cancel_date'].isnull() == True)]\n",
    "undecide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick x-features & fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfinal = trval[['package_type', 'num_weekly_services_utilized',\n",
    "       'preferred_genre', 'intended_use', 'weekly_consumption_hour',\n",
    "       'num_ideal_streaming_services', 'age', 'male_TF',\n",
    "       'attribution_technical', 'op_sys', 'join_fee']]\n",
    "yfinal = trval[['churn']]\n",
    "\n",
    "#X_un = undecide[['package_type', 'num_weekly_services_utilized',\n",
    "#       'preferred_genre', 'intended_use', 'weekly_consumption_hour',\n",
    "#       'num_ideal_streaming_services', 'age', 'male_TF',\n",
    "#       'attribution_technical', 'op_sys', 'join_fee']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfinal =  pd.get_dummies(Xfinal,drop_first = True)\n",
    "#X_un =  pd.get_dummies(X_un,drop_first = True)\n",
    "#X_un.info()\n",
    "#yfinal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate train-test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xfinal, yfinal, test_size=0.30, random_state=1997)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization with minmax\n",
    "#change from dataframe to array\n",
    "minmaxscaler = MinMaxScaler()\n",
    "X_train = minmaxscaler.fit_transform(X_train) \n",
    "X_val = minmaxscaler.fit_transform(X_val) \n",
    "#X_un = minmaxscaler.fit_transform(X_un) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred=logreg.predict(X_val)\n",
    "\n",
    "# predict probabilities\n",
    "y_pred_prob=logreg.predict_proba(X_val)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_pred_prob = y_pred_prob[:, 1]\n",
    "# from 2-dimension to 1-dimension \n",
    "y_valTranf= y_val['churn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc score\n",
    "log_auc = roc_auc_score(y_valTranf, y_pred_prob)\n",
    "log_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_valTranf,y_pred,rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ',metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "print('Recall: ',metrics.recall_score(y_val, y_pred))\n",
    "\n",
    "print('Precision: ',metrics.precision_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
